import argparse
from pathlib import Path
import torch.multiprocessing as mp
from multiprocessing import Manager

from datamodule import EmotionDataset
from datamodule_korean import KoreanEmotionDataset
from data_loader import (
    build_few_shot_examples,
    build_few_shot_prompt,
    extrat_emotion_ko_from_output,
    ko_to_en_motion,
    en_id_to_ko,
    EMOTION_EN,
)

import model.qwen as qwen
import model.llama as llama
import model.ministral as ministral
import model.solar as solar
import model.gpt as gpt

DATA_PATH = "dair-ai/emotion"

def get_model_generate(model_name):
    model_name = model_name.lower()

    if model_name == "qwen":
        return qwen.generate
    elif model_name == "llama":
        return llama.generate
    elif model_name == "ministral":
        return ministral.generate
    elif model_name == "solar":
        return solar.generate
    elif model_name == "gpt":
        return gpt.generate
    else:
        raise ValueError(f"Unkown model name!")

def parse_args():
    parser = argparse.ArgumentParser("Few-shot Emotion Classificaiton")
    parser.add_argument(
        "--model_name",
        type = str,
        required = True,
        help = "qwen , llama, ministrial, solar, gpt"
    )
    parser.add_argument(
        "--shots",
        type = int,
        default = 2,
        help = "few-shot ìˆ˜"
    )
    parser.add_argument(
        "--samples",
        type = int,
        default = 200,
        help = "í…ŒìŠ¤íŠ¸ì— ì‚¬ìš©í•  ìµœëŒ€ ìƒ˜í”Œ ìˆ˜"
    )
    parser.add_argument(
        "--gpus",
        type = str,
        default = "0,1,2",
        help = "ì‚¬ìš©í•  GPU IDs (ì½¤ë§ˆë¡œ êµ¬ë¶„, ì˜ˆ: 0,1,2)"
    )
    parser.add_argument(
        "--result_name",
        type = str,
        default = None,
        help = "ê²°ê³¼ íŒŒì¼ëª… (ê¸°ë³¸ê°’: ëª¨ë¸ëª…_result.txt)"
    )
    parser.add_argument(
        "--use_korean",
        action = "store_true",
        help = "í•œêµ­ì–´ë¡œ ë²ˆì—­ëœ ë°ì´í„°ì…‹ ì‚¬ìš©"
    )
    parser.add_argument(
        "--korean_data_dir",
        type = str,
        default = "./korean_emotion_data",
        help = "í•œêµ­ì–´ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--debug",
        action = "store_true",
        help = "ë””ë²„ê·¸ ëª¨ë“œ: í•˜ë‚˜ì˜ ìƒ˜í”Œë§Œ í…ŒìŠ¤íŠ¸ (--samplesëŠ” ìƒ˜í”Œ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©)"
    )
    return parser.parse_args()

def worker_process(gpu_id, model_name, few_shot_examples, test_samples, results_dict, worker_id):
    """
    ê° GPUì—ì„œ ì‹¤í–‰ë  ì›Œì»¤ í”„ë¡œì„¸ìŠ¤
    """
    import os
    os.environ["CUDA_VISIBLE_DEVICES"] = str(gpu_id)

    print(f"[Worker {worker_id}] GPU {gpu_id}ì—ì„œ {len(test_samples)}ê°œ ìƒ˜í”Œ ì²˜ë¦¬ ì‹œì‘")

    generate = get_model_generate(model_name)

    correct = 0
    total = 0

    for i, sample in enumerate(test_samples):
        text = sample["text"]
        label_id = sample["label_id"]

        gold_en = EMOTION_EN[label_id]
        gold_ko = en_id_to_ko(label_id)

        prompt = build_few_shot_prompt(few_shot_examples, text)
        output = generate(prompt, max_new_tokens=32, gpu_id=0)  # CUDA_VISIBLE_DEVICESë¡œ ì¸í•´ í•­ìƒ 0

        pred_ko = extrat_emotion_ko_from_output(output)

        total += 1
        if pred_ko == gold_ko:
            correct += 1

        if (i + 1) % 10 == 0:
            print(f"[Worker {worker_id}] ì§„í–‰: {i+1}/{len(test_samples)}")

    results_dict[worker_id] = {"correct": correct, "total": total}
    print(f"[Worker {worker_id}] ì™„ë£Œ: {correct}/{total}")
    
def main():
    mp.set_start_method('spawn', force=True)

    args = parse_args()

    model_name = args.model_name.lower()
    K_PER_LABEL = args.shots
    MAX_SAMPLES = args.samples
    gpu_ids = [int(x.strip()) for x in args.gpus.split(",")]

    print(f"[INFO] ëª¨ë¸ ì„ íƒ : {model_name}")
    print(f"[INFO] Few-shot per label : {K_PER_LABEL}")
    print(f"[INFO] ì‚¬ìš©í•  GPU : {gpu_ids}")
    print(f"[INFO] í•œêµ­ì–´ ë°ì´í„°ì…‹ ì‚¬ìš© : {args.use_korean}")

    # ë°ì´í„°ì…‹ ì„ íƒ
    if args.use_korean:
        # Zero-shotì´ë©´ train_ds í•„ìš” ì—†ìŒ
        if K_PER_LABEL > 0:
            train_ds = KoreanEmotionDataset(args.korean_data_dir, seed = 42, split = "train")
        test_ds = KoreanEmotionDataset(args.korean_data_dir, seed = 42, split = "test")
    else:
        if K_PER_LABEL > 0:
            train_ds = EmotionDataset(DATA_PATH, seed = 42, split = "train")
        test_ds = EmotionDataset(DATA_PATH, seed = 42, split = "test")

    # Few-shot examples ìƒì„± (K_PER_LABEL > 0ì¼ ë•Œë§Œ)
    if K_PER_LABEL > 0:
        few_shot_examples = build_few_shot_examples(train_ds.dataset, K_PER_LABEL)
    else:
        few_shot_examples = []

    # ë””ë²„ê·¸ ëª¨ë“œ: ë‹¨ì¼ ìƒ˜í”Œë§Œ í…ŒìŠ¤íŠ¸
    if args.debug:
        sample_idx = MAX_SAMPLES  # --samplesë¥¼ ì¸ë±ìŠ¤ë¡œ ì‚¬ìš©
        sample = test_ds[sample_idx]

        print(f"\n{'='*60}")
        print(f"ğŸ” ë””ë²„ê·¸ ëª¨ë“œ (ìƒ˜í”Œ ì¸ë±ìŠ¤: {sample_idx})")
        print(f"{'='*60}\n")
        print(f"ğŸ“ ì…ë ¥ í…ìŠ¤íŠ¸:")
        print(f"   {sample['text']}\n")
        print(f"âœ… ì •ë‹µ ë ˆì´ë¸”:")
        print(f"   label: {sample['label']}")
        print(f"   label_id: {sample['label_id']}\n")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = build_few_shot_prompt(
            test_text=sample["text"],
            few_shot_examples=few_shot_examples
        )

        print(f"ğŸ’¬ í”„ë¡¬í”„íŠ¸:")
        print(f"{'-'*60}")
        print(prompt)
        print(f"{'-'*60}\n")

        # ëª¨ë¸ ì˜ˆì¸¡
        generate = get_model_generate(model_name)
        print(f"ğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
        output = generate(prompt, max_new_tokens=32, gpu_id=gpu_ids[0])

        print(f"\nğŸ“¤ ëª¨ë¸ ì¶œë ¥ (raw):")
        print(f"   '{output}'\n")

        # ê°ì • ì¶”ì¶œ
        pred_emotion = extrat_emotion_ko_from_output(output)
        print(f"ğŸ¯ ì˜ˆì¸¡ ë ˆì´ë¸”:")
        print(f"   {pred_emotion}\n")

        # ì •ë‹µ ë¹„êµ
        is_correct = (pred_emotion == sample['label'])
        result_emoji = "âœ…" if is_correct else "âŒ"
        print(f"{result_emoji} ê²°ê³¼: {'ì •ë‹µ' if is_correct else 'ì˜¤ë‹µ'}")
        print(f"\n{'='*60}\n")
        return

    # í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¤€ë¹„
    num_samples = min(MAX_SAMPLES, len(test_ds))
    test_samples = [test_ds[i] for i in range(num_samples)]

    # ìƒ˜í”Œì„ GPU ê°œìˆ˜ë§Œí¼ ë¶„í• 
    num_gpus = len(gpu_ids)
    samples_per_gpu = len(test_samples) // num_gpus
    remainder = len(test_samples) % num_gpus

    sample_chunks = []
    start_idx = 0
    for i in range(num_gpus):
        # ë‚˜ë¨¸ì§€ë¥¼ ì•ìª½ GPUë“¤ì— ë¶„ë°°
        chunk_size = samples_per_gpu + (1 if i < remainder else 0)
        end_idx = start_idx + chunk_size
        sample_chunks.append(test_samples[start_idx:end_idx])
        start_idx = end_idx

    print(f"[INFO] ì´ {len(test_samples)}ê°œ ìƒ˜í”Œì„ {num_gpus}ê°œ GPUë¡œ ë¶„í• :")
    for i, chunk in enumerate(sample_chunks):
        print(f"  GPU {gpu_ids[i]}: {len(chunk)}ê°œ ìƒ˜í”Œ")

    # ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ë³‘ë ¬ ì‹¤í–‰
    manager = Manager()
    results_dict = manager.dict()

    processes = []
    for i, gpu_id in enumerate(gpu_ids):
        p = mp.Process(
            target=worker_process,
            args=(gpu_id, model_name, few_shot_examples, sample_chunks[i], results_dict, i)
        )
        p.start()
        processes.append(p)

    # ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸°
    for p in processes:
        p.join()

    # ê²°ê³¼ ì§‘ê³„
    total_correct = 0
    total_samples = 0
    for worker_id in range(num_gpus):
        result = results_dict[worker_id]
        total_correct += result["correct"]
        total_samples += result["total"]
        print(f"[ê²°ê³¼] Worker {worker_id}: {result['correct']}/{result['total']}")

    acc = total_correct / total_samples if total_samples > 0 else 0.0

    # ê²°ê³¼ ì €ì¥
    log_lines = []
    log_lines.append(f"Model : {model_name}\n")
    log_lines.append(f"GPUs : {gpu_ids}\n")
    log_lines.append(f"Few-shot per label : {K_PER_LABEL}\n")
    log_lines.append("\n==== Final Result ====\n")
    log_lines.append(f"Accuracy : {acc:.4f}\n")
    log_lines.append(f"Correct : {total_correct}/{total_samples}\n")

    results_dir = Path("/home/eastj/study/capstone/results")
    results_dir.mkdir(exist_ok = True)

    result_filename = args.result_name if args.result_name else f"{model_name}_result.txt"
    out_path = results_dir / result_filename
    with out_path.open("w", encoding = "utf-8") as f:
        f.writelines(log_lines)

    print(f'\n[INFO] ìµœì¢… ì •í™•ë„: {acc:.4f} ({total_correct}/{total_samples})')
    print(f'[INFO] ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {out_path}')


if __name__ == "__main__":
    main()